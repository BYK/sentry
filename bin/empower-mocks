#!/usr/bin/env python
from sentry.runner import configure

configure()

import hashlib
import re
import subprocess
import sys
import uuid
from argparse import ArgumentParser
from datetime import datetime, timezone

import click
import requests
from django.conf import settings

from sentry import buffer
from sentry.models.projectkey import ProjectKey
from sentry.utils.mockdata import get_organization
from sentry.utils.mockdata.core import generate_projects

GCP_BUCKET = "empower-mocks-production"

# TODO: do mapping on empower/mini-relay side as it has control over project ids
EMPOWER_PROJECT_IDS = {
    "react": 2,
    "flask": 3,
    "ruby": 4,
}

PROJECT_PLATFORM_MAP = {
    "react": "javascript-react",
    "flask": "python-flask",
    "ruby": "ruby",
}


def download_file(url):
    try:
        response = requests.get(url)
        if response.status_code == 200:
            return response.content
        elif response.status_code == 404:
            return None
        else:
            response.raise_for_status()  # This will raise an HTTPError
    except requests.exceptions.RequestException as e:
        raise Exception(f"An error occurred while downloading the file: {str(e)}")


def get_envelopes(project_name):
    project_id = EMPOWER_PROJECT_IDS[project_name]
    res = []
    i = 1
    while True:
        envelope = download_file(f"http://{GCP_BUCKET}.storage.googleapis.com/{project_id}/{i}")
        if envelope is None:
            break
        res.append(envelope)
        i += 1
    return res


def send_envelope_into_ingest(envelope, project_id, public_key):

    # TODO these are part of URL path so should be parsed out of the envelope:
    # &sentry_version=7&sentry_client=sentry.javascript.react%2F8.20.0
    subprocess.run(
        [
            "curl",
            "-X",
            "POST",
            f"http://dev.getsentry.net:8000/api/{project_id}/envelope/?sentry_key={public_key}",
            "-H",
            "content-type: text/plain;charset=UTF-8",
            "-d",
            envelope,
        ]
    )
    click.echo("")
    # click.echo("Sent envelope: " + envelope.decode("utf-8"))


def decode_if_needed(str_or_bytes):
    if type(str_or_bytes) is not str:
        return str_or_bytes.decode("utf-8")
    return str_or_bytes


def iso2dt(iso_str):
    return datetime.strptime(decode_if_needed(iso_str), "%Y-%m-%dT%H:%M:%S.%fZ").replace(
        tzinfo=timezone.utc
    )


def dt2iso(dt):
    return dt.strftime("%Y-%m-%dT%H:%M:%S.%f") + "Z"


def unix2dt(unix_str):
    return datetime.fromtimestamp(float(decode_if_needed(unix_str))).replace(tzinfo=timezone.utc)


def dt2unix(dt):
    return f"{dt.timestamp():.7f}"


# Shift all timestamps by equal amount so that the latest timestamp found becomes `base_time`
#
# NOTE: this can potentially mess up JSON in breadcrumbs, HTTP response bodies, etc.
# but we don't care if that happens as this is demo data and those values can be anything.
# What's potentially undesirable is if extraneous timestamps happens to the latest timestamp
# that's why we try to match keys to reduce the chance of that happening.
def shift_all_timestamps(envelope, base_time=None):
    base_time = base_time or datetime.now(timezone.utc)
    iso_8601_re = rb"(\"(?:start_timestamp|timestamp|started|sent_at)\":\")(\d{4}-\d{2}-\d{2}T\d{2}:\d{2}:\d{2}\.\d{3,9}Z)(\")"
    unix_fract_re = (
        rb"(\"(?:start_timestamp|timestamp|started|sent_at)\":)(\d{10}\.\d{3,9})([^0-9])"
    )

    datetime_objects = [iso2dt(m[1].decode("utf-8")) for m in re.findall(iso_8601_re, envelope)] + [
        unix2dt(m[1].decode("utf-8")) for m in re.findall(unix_fract_re, envelope)
    ]
    if not datetime_objects:
        click.echo(f"[WARNING] No timestamps found in input string: {envelope}")
        return envelope
    latest_time = max(datetime_objects)
    offset = base_time - latest_time

    return re.sub(
        iso_8601_re,
        lambda m: m.group(1) + dt2iso(iso2dt(m.group(2)) + offset).encode("utf-8") + m.group(3),
        re.sub(
            unix_fract_re,
            lambda m: m.group(1)
            + dt2unix(unix2dt(m.group(2)) + offset).encode("utf-8")
            + m.group(3),
            envelope,
        ),
    )


# Replace all ID with their salted hashes
# All envelopes in the same Replay session must be treated as a single unit to preserve the relationships
# between events via replay_id and trace_id
def make_all_ids_unique(envelopes, batch_salt=""):
    uuid32_re = (
        rb'("(?:id|event_id|trace_id|profile_id|replay_id|replayId|message|sid)":")([0-9a-f]{32})"'
    )
    id16_re = rb'("(?:parent_span_id|span_id|__span)":")([0-9a-f]{16})"'

    new_envelopes = []
    for envelope in envelopes:
        new_envelopes.append(
            re.sub(
                uuid32_re,
                lambda t: t.group(1)
                + hashlib.sha256(t.group(2) + batch_salt).hexdigest()[:32].encode("utf-8")
                + b'"',
                re.sub(
                    id16_re,
                    lambda t: t.group(1)
                    + hashlib.sha256(t.group(2) + batch_salt).hexdigest()[:16].encode("utf-8")
                    + b'"',
                    envelope,
                ),
            )
        )
    return new_envelopes


if __name__ == "__main__":
    try:
        settings.CELERY_ALWAYS_EAGER = True

        parser = ArgumentParser(description="Load latest mock data from empower")
        parser.add_argument(
            "-p",
            "--projects",
            default=["react", "flask"],
            nargs="+",
            help="List of empower projects",
        )
        options = parser.parse_args()

        ingest_running = (
            subprocess.run(
                ["pgrep", "-fl", "sentry run consumer ingest-events"],
                stdout=subprocess.DEVNULL,
                stderr=subprocess.DEVNULL,
            ).returncode
            == 0
        )
        if not ingest_running:
            click.echo(
                "Ingest is required for empower-mocks but is not running. Please follow https://develop.sentry.dev/development/environment/#ingestion-pipeline-relay-aka-sending-events-to-your-dev-environment"
            )
            sys.exit(1)

        organization = get_organization()
        project_map = generate_projects(
            organization, tuple([("Empower Plant", tuple(p for p in options.projects))])
        )

        # [ {envelope: bytes, dev_project_id: int, dev_project_public_key: str} ]

        batch_time = datetime.now(timezone.utc)
        batch_salt = uuid.uuid4().hex.encode("utf-8")

        for project_name in options.projects:
            # TODO: first update platform, get envelopes, then send as separate step/loop
            project = project_map[project_name]
            project.platform = PROJECT_PLATFORM_MAP[project_name]
            project.save()
            project_public_key = ProjectKey.get_default(project)

            envelopes = get_envelopes(project_name)
            envelopes = make_all_ids_unique(envelopes, batch_salt)
            for envelope in envelopes:
                send_envelope_into_ingest(
                    shift_all_timestamps(envelope, base_time=batch_time),
                    project.id,
                    project_public_key,
                )

        click.echo("    > Done sending envelopes. Waiting for processing to finish")

        if hasattr(buffer, "process_pending"):
            click.echo("    > Processing pending buffers")
            buffer.process_pending()

        click.echo("    > Processing complete")

    except Exception:
        # Avoid reporting any issues recursively back into Sentry
        import sys
        import traceback

        traceback.print_exc()
        sys.exit(1)
